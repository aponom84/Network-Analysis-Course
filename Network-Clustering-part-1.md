# **Кластеризация в сетях — Часть 1 – поиск непересекающихся сообществ**

## **1. Введение: Что такое кластер (сообщество) в сети?**

Согласно классическому определению из социальной сетевой аналитики (Wasserman & Faust, 1994):

> *«Сообщество — это подмножество акторов, между которыми существуют относительно сильные, прямые, интенсивные, частые или позитивные связи».*

Это означает, что в рамках одного кластера (сообщества) вершины графа тесно связаны между собой, тогда как связи между разными кластерами слабее или реже. Цель кластеризации — выявить такую структуру в графе без предварительной разметки.

---

## **2. Основные подходы к кластеризации в сетях**

Существует множество методов, которые можно условно разделить на следующие категории:

| Категория | Примеры методов |
|----------|------------------|
| **Распространение меток** | Label Propagation Algorithm (LPA) |
| **Оптимизация целевой функции** | Максимизация модулярности, минимизация разреза |
| **Методы, основанные на расстоянии** | Кластеризация по кратчайшим путям, метрикам на графах |
| **Спектральные методы** | Spectral clustering (через собственные векторы матриц Лапласа) |
| **Жадные алгоритмы** | Greedy Clique Extension, Louvain |
| **Точные методы** | Mixed Integer Programming (MIP) |
| **Современные ML-подходы** | Graph Neural Networks (GNNs) |

---

## **3. Методы разрезания графа (Graph Partitioning)**

Эти методы стремятся разбить граф на *k* частей, минимизируя «разрез» — число рёбер между кластерами. Однако простой минимум числа рёбер часто приводит к несбалансированным кластерам (например, один кластер — одна вершина).

### **3.1. Minimum Cut**
- Цель: минимизировать число рёбер между двумя частями графа.
- Решается за полиномиальное время (алгоритм **Stoer–Wagner**).
- Обобщение: **Minimum k-cut** — разбиение на *k* компонент. Полиномиален при фиксированном *k*, но становится вычислительно тяжёлым при больших *k*.

### **3.2. Ratio Cut**
Предложен Wei & Cheng (1991) для задач проектирования интегральных схем.  
Формула:
$$
\text{RatioCut}(C_1, ..., C_k) = \sum_{i=1}^k \frac{\text{cut}(C_i, \overline{C_i})}{|C_i|}
$$
- Учитывает **размер кластера**: штрафует маленькие кластеры.
- Позволяет избежать тривиальных решений.

### **3.3. Normalized Cut (Ncut)**
Предложен Shi & Malik (2000) для сегментации изображений.  
Формула:
$$
\text{Ncut}(C_1, ..., C_k) = \sum_{i=1}^k \frac{\text{cut}(C_i, \overline{C_i})}{\text{vol}(C_i)}
$$
где $\text{vol}(C_i) = \sum_{v \in C_i} \deg(v)$ — сумма степеней вершин в кластере.  
- Учитывает **степени вершин**, а не просто количество узлов.
- Лучше подходит для неоднородных графов.

### **3.4. Min-Max Cut**
Предложен Ding et al. (2001).  
Цель: одновременно **минимизировать межкластерные связи** и **максимизировать внутрекластерные связи**.  
Это делает разбиение более «естественным» — кластеры становятся плотными внутри и слабо связанными снаружи.

---

## **4. Модулярность (Modularity) и Configuration Model**

### **4.1. Configuration Model**
— это **нулевая модель** (null model) для сравнения: случайный граф с тем же распределением степеней, что и исходный, но с произвольно перераспределёнными рёбрами.

Идея: если в реальном графе внутри кластера рёбер **больше**, чем в случайном графе с теми же степенями, то это указывает на наличие структуры.

### **4.2. Формула модулярности Q**
$$
Q = \frac{1}{2m} \sum_{i,j} \left( A_{ij} - \frac{k_i k_j}{2m} \right) \delta(C(i), C(j))
$$

где:
- $A_{ij}$ — элемент матрицы смежности (1, если есть ребро между *i* и *j*, иначе 0),
- $k_i, k_j$ — степени вершин *i* и *j*,
- $m$ — общее число рёбер,
- $\delta(C(i), C(j))$ — функция Кронекера: 1, если вершины в одном кластере, иначе 0.

**Интерпретация:**
- Первое слагаемое — доля рёбер **внутри кластеров**.
- Второе — ожидаемая доля таких рёбер в **случайном графе** с теми же степенями.
- Таким образом, **Q ∈ [−0.5, 1]**, и чем выше Q, тем лучше разбиение.

### **4.3. Примеры применения**
- **Karate Club Network** (Зачись-клуб): алгоритм, максимизирующий Q, воспроизвёл реальное раскол графа на два сообщества — **точно**.
- **Dolphins Network**: сеть из 62 дельфинов и 159 связей (частые взаимодействия). Модулярность помогла выявить два основных подсообщества.

---

## **5. Алгоритмы максимизации модулярности**

Поскольку точная оптимизация Q — NP-трудная задача, используются эвристики:

| Алгоритм | Год | Особенности |
|--------|-----|-------------|
| **Newman’s Fast Algorithm** | 2004 | Иерархическая агломерация: на каждом шаге объединяются кластеры, дающие наибольший прирост Q |
| **Clauset–Newman–Moore (CNM)** | 2004 | Оптимизирован для **очень больших сетей** (миллионы узлов) |
| **Louvain Algorithm** | 2008 | Двухфазный: локальная оптимизация + агрегация графа. Очень быстрый и масштабируемый |
| **Wakita–Tsurumi** | — | Адаптация Louvain для социальных сетей |
| **Guillaume et al.** | 2008 | Улучшенная реализация Louvain |

> **Louvain** — один из самых популярных алгоритмов на практике благодаря балансу скорости и качества.

---

## **6. Критика модулярности: «Не серебряная пуля»**

Несмотря на популярность, модулярность имеет **существенные ограничения**:

### **6.1. Проблема разрешения (Resolution Limit)**
- В больших сетях модулярность **не способна обнаруживать малые сообщества**, даже если они плотные.
- Причина: сравнение с глобальной нулевой моделью (весь граф), а не локальной.

### **6.2. Вырожденность решений**
- Существует **огромное число разбиений** с почти одинаковыми значениями Q.
- Это делает результат **нестабильным** и трудно интерпретируемым.

### **6.3. Пример, где модулярность «не имеет смысла»**
В презентации упомянут контрпример (без деталей), где максимизация Q приводит к **контринтуитивному или ошибочному разбиению**. Это подчёркивает: **модулярность — лишь одна из возможных мер**, и её нельзя применять слепо.

---

## **7. Label Propagation Algorithm (LPA)**
- Каждая вершина изначально имеет уникальную метку.
- На каждой итерации вершина принимает **наиболее частую метку среди соседей**.
- Алгоритм сходится быстро (часто за 5–10 итераций).
- **Плюсы**: простота, линейная сложность.
- **Минусы**: нестабильность (результат зависит от порядка обновления), возможны «большие» кластеры.

Благодарю за уточнение! Теперь я вижу, что слайд **«Methods based on MIP»** содержит не общее описание MIP, а конкретную **математическую формулировку задачи кластеризации на основе MIP**, с целевой функцией и ограничениями. Это важный технический момент.

Вот **исправленный и детализированный раздел конспекта**, полностью соответствующий содержанию этого слайда:

---

## **8. Методы на основе Mixed Integer Programming (MIP): Конкретная формулировка**

Пример **конкретной MIP-формулировки задачи кластеризации**, минимизирующий сумму двух параметров: максимальный диаметр кластера и максимальное число внешних связей вершины в кластере.

### **Целевая функция**
$$
\text{Minimize} \quad D_{max} + k^{out}_{max}
$$

где:
- $D_{max}$ — **максимальный диаметр среди всех кластеров** (длина самого длинного пути между двумя вершинами внутри одного кластера),
- $k^{out}_{max}$ — **максимальное количество рёбер, исходящих из любой вершины кластера во внешние вершины** (внешняя степень).

Эта цель стремится создать **компактные и «закрытые» кластеры**: малый диаметр означает, что все вершины внутри кластера близки друг к другу, а малое $k^{out}_{max}$ означает, что кластер слабо связан с остальной сетью.

---

### **Ограничения (Constraints)**

Обозначения:
- $n$ — общее число объектов (вершин),
- $c_0$ — заданное число кластеров,
- $d_{ij}$ — расстояние по кратчайшему пути между объектами $i$ и $j$,
- $A_{ij}$ — элемент матрицы смежности: 1, если объекты $i$ и $j$ соединены ребром, иначе 0,
- $x_{ic}$ — **бинарная переменная решения**: 1, если объект $i$ принадлежит кластеру $c$, иначе 0.

#### **(1) Ограничение на диаметр кластера**
$$
D_{max} \geq d_{ij}(x_{ic} + x_{jc} - 1) \quad \forall \; i,j,c \; \text{ such that } i < j
$$
- Если оба объекта $i$ и $j$ принадлежат одному кластеру $c$ ($x_{ic} = x_{jc} = 1$), то $D_{max}$ должна быть не меньше расстояния $d_{ij}$.
- Если хотя бы один объект не в кластере $c$, то правая часть ≤ 0, и ограничение выполняется автоматически.
- Таким образом, $D_{max}$ будет равна **максимальному расстоянию между любыми двумя вершинами в одном кластере**.

#### **(2) Каждый объект должен принадлежать ровно одному кластеру**
$$
\sum_{c=1}^{c_0} x_{ic} = 1 \quad \forall i
$$
- Гарантирует, что разбиение является **разделением** (partition), а не покрытием.

#### **(3) Каждый кластер должен содержать хотя бы одну вершину**
$$
\sum_{i=1}^{n} x_{ic} \geq 1 \quad \forall c
$$
- Предотвращает появление пустых кластеров.

#### **(4) Внутренняя плотность кластера (ограничение на минимальную связность)**
$$
\sum_{j=1}^{n} A_{ij} x_{jc} \geq x_{ic} \left( \frac{\sum_{j=1}^{n} A_{ij}}{2} \right) \quad \forall i, c
$$
- Левая часть: сумма связей вершины $i$ с другими вершинами *внутри* кластера $c$.
- Правая часть: половина от общей степени вершины $i$ (т.е. требует, чтобы вершина имела **не менее половины своих связей внутри своего кластера**).
- Это условие способствует формированию **плотных сообществ**.

#### **(5) Ограничение на внешнюю степень вершины**
$$
\sum_{j=1}^{n} A_{ij} x_{jc} \geq x_{ic} \sum_{j=1}^{n} A_{ij} - k^{out}_{max} \quad \forall i, c
$$
- Перепишем:  
  $$
  k^{out}_{max} \geq x_{ic} \sum_{j=1}^{n} A_{ij} - \sum_{j=1}^{n} A_{ij} x_{jc}
  $$
- Правая часть — это **число рёбер, исходящих из вершины $i$ вне кластера $c$** (если $x_{ic}=1$).
- Таким образом, $k^{out}_{max}$ ограничивает **максимальную внешнюю степень** любой вершины в любом кластере.

#### **(6) Бинарность переменных**
$$
x_{ic} \in \{0, 1\} \quad \forall i, c
$$

#### **(7) Неотрицательность вспомогательных переменных**
$$
D_{max}, k^{out}_{max} \geq 0
$$

---

### **Интерпретация модели**

Эта MIP-формулировка решает задачу **кластеризации с жёсткими ограничениями на структуру кластеров**:
- **Компактность** (через $D_{max}$),
- **Связность внутри кластера** (ограничение 4),
- **Изолированность от внешнего мира** (через $k^{out}_{max}$),
- **Полное разбиение** (ограничения 2 и 3).

Такой подход особенно полезен, когда требуется **высококачественное, контролируемое разбиение** — например, в биоинформатике (кластеризация белков), социологии (выделение групп с высокой внутренней коэзивностью) или при проектировании сетевых систем.

---

### **Практические особенности**

- **Вычислительная сложность**: Эта модель содержит $O(n^2 c_0)$ переменных и ограничений, что делает её применимой только для **небольших графов** (до ~100–200 вершин).
- **Решатели**: Для решения таких задач используются коммерческие или открытые MIP-решатели (Gurobi, CPLEX, SCIP, CBC).
- **Преимущество**: Дает **гарантированно оптимальное решение** по заданной целевой функции и ограничениям — в отличие от эвристических методов (Louvain, LPA).
